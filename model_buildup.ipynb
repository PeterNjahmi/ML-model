{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the modules\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from sklearn.tree import plot_tree\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.utils import resample\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "df = pd.read_csv('fraud_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To observe the dimensions of the dataset we're dealing with\n",
    "\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get insights about the different data types \n",
    "\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Observe the first 5 rows of the dataset\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the number of columns\n",
    "num_columns = len(df.columns)\n",
    "\n",
    "# Print the number of columns\n",
    "print(\"Number of columns:\", num_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the number of rows\n",
    "num_rows = len(df)\n",
    "\n",
    "# Print the number of rows\n",
    "print(\"Number of rows:\", num_rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the columns with NaN values and their counts\n",
    "nan_columns = df.columns[df.isna().any()]\n",
    "nan_counts = df[nan_columns].isna().sum()\n",
    "\n",
    "# Print the columns with NaN values and their counts\n",
    "for column, count in zip(nan_columns, nan_counts):\n",
    "    print(f\"Column '{column}' has {count} NaN values.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the columns with at least 30,000 NaN values\n",
    "nan_columns = df.columns[df.isna().sum() >= 30000]\n",
    "\n",
    "# Drop the columns with at least 1000 NaN values\n",
    "df.drop(nan_columns, axis=1, inplace=True)\n",
    "\n",
    "# Print the updated DataFrame\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# observing updated first 5 rows\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Get the columns with more than 1000 zeroes\n",
    "# zero_columns = df.columns[(df == 0).sum() > 30000]\n",
    "\n",
    "# # Drop the columns with more than 1000 zeroes\n",
    "# df.drop(zero_columns, axis=1, inplace=True)\n",
    "\n",
    "# # Print the updated DataFrame\n",
    "# df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the columns with NaN values and their counts\n",
    "nan_columns = df.columns[df.isna().any()]\n",
    "nan_counts = df[nan_columns].isna().sum()\n",
    "\n",
    "# Print the columns with NaN values and their counts\n",
    "for column, count in zip(nan_columns, nan_counts):\n",
    "    print(f\"Column '{column}' has {count} NaN values.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the numerical columns\n",
    "numerical_columns = df.select_dtypes(include='number').columns\n",
    "\n",
    "# Replace NaN values with column means\n",
    "df[numerical_columns] = df[numerical_columns].fillna(df[numerical_columns].mean())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get Remaining columns with NaN values and their counts\n",
    "nan_columns = df.columns[df.isna().any()]\n",
    "nan_counts = df[nan_columns].isna().sum()\n",
    "\n",
    "# Print the columns with NaN values and their counts\n",
    "for column, count in zip(nan_columns, nan_counts):\n",
    "    print(f\"Column '{column}' has {count} NaN values.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the columns with NaN values and their counts\n",
    "nan_columns = df.columns[df.isna().any()]\n",
    "nan_counts = df[nan_columns].isna().sum()\n",
    "\n",
    "# Get the data types of the columns\n",
    "column_types = df[nan_columns].dtypes\n",
    "\n",
    "# Print the columns with NaN values, their counts, and data types\n",
    "for column, count, dtype in zip(nan_columns, nan_counts, column_types):\n",
    "    print(f\"Column '{column}' has {count} NaN values. Data type: {dtype}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nan_columns = df.columns[df.isna().any()]\n",
    "\n",
    "# Replace NaN values with the mode\n",
    "for column in nan_columns:\n",
    "    mode_value = df[column].mode().iloc[0]\n",
    "    df[column].fillna(mode_value, inplace=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get Remaining columns with NaN values and their counts\n",
    "nan_columns = df.columns[df.isna().any()]\n",
    "nan_counts = df[nan_columns].isna().sum()\n",
    "\n",
    "# Print the columns with NaN values and their counts\n",
    "for column, count in zip(nan_columns, nan_counts):\n",
    "    print(f\"Column '{column}' has {count} NaN values.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if there are any remaining NaN values\n",
    "has_nan = df.isnull().values.any()\n",
    "\n",
    "# Print the result\n",
    "if has_nan:\n",
    "    print(\"There are still NaN values in the dataset.\")\n",
    "else:\n",
    "    print(\"There are no NaN values in the dataset.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Dropping Columns with all zeroes\n",
    "\n",
    "# # Drop the specified columns\n",
    "# columns_to_drop = ['column1', 'column2', 'column3']\n",
    "# df = df.drop(columns_to_drop, axis=1)\n",
    "\n",
    "# # Use the modified DataFrame for further analysis or modeling\n",
    "\n",
    "# # Check if all entries in a specific column are zeroes\n",
    "# column_name = 'V321'\n",
    "# are_all_zeroes = (df[column_name] == 0).all()\n",
    "\n",
    "# # Print the result\n",
    "# if are_all_zeroes:\n",
    "#     print(\"All entries in '{}' column are zeroes.\".format(column_name))\n",
    "# else:\n",
    "#     print(\"Not all entries in '{}' column are zeroes.\".format(column_name))\n",
    "\n",
    "# # Check how many entries in a specific column are zeroes\n",
    "# import pandas as pd\n",
    "\n",
    "# # Read the dataset into a DataFrame\n",
    "# df = pd.read_csv('your_dataset.csv')\n",
    "\n",
    "# # Check how many entries in multiple columns are zeroes\n",
    "# columns_to_check = ['V321', 'V320', 'V319']\n",
    "# num_zero_entries = (df[columns_to_check] == 0).all(axis=1).sum()\n",
    "\n",
    "# # Print the result\n",
    "# print(\"Number of zero entries across the specified columns: \", num_zero_entries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for duplicates\n",
    "duplicates = df.duplicated()\n",
    "\n",
    "# Print the result\n",
    "if duplicates.any():\n",
    "    print(\"There are duplicates in the dataset.\")\n",
    "else:\n",
    "    print(\"There are no duplicates in the dataset.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if for in df == 1:\n",
    "# print(element)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Histogram distribtution of isFraud\n",
    "feature = df['isFraud']\n",
    "\n",
    "# Create a histogram\n",
    "plt.hist(feature, bins=10)  # Adjust the number of bins as needed\n",
    "\n",
    "# Set labels and title\n",
    "plt.xlabel('Feature')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Histogram of isFraud')\n",
    "\n",
    "# Display the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pie Chart for ProductCD\n",
    "\n",
    "top10 = df['ProductCD'].value_counts()[:10]\n",
    "plt.pie(top10, labels=top10.index, autopct=\"%1.1f%%\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pie Chart view for card4\n",
    "\n",
    "top10 = df['card4'].value_counts()[:10]\n",
    "plt.pie(top10, labels=top10.index, autopct=\"%1.1f%%\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizing the Distribution of TransactionID and card4\n",
    "feature1 = df['card4']\n",
    "feature2 = df['TransactionID']\n",
    "\n",
    "# Create a scatter plot using Seaborn\n",
    "sns.scatterplot(x=feature1, y=feature2)\n",
    "\n",
    "# Set labels and title\n",
    "plt.xlabel('Feature 1')\n",
    "plt.ylabel('Feature 2')\n",
    "plt.title('Scatter Plot of card4 vs TransactionID')\n",
    "\n",
    "# Display the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Handling Undersampling in isFraud\n",
    "\n",
    "# Separate the majority and minority classes\n",
    "majority_class = df[df['isFraud'] == 0]\n",
    "minority_class = df[df['isFraud'] == 1]\n",
    "\n",
    "# Undersample the majority class\n",
    "undersampled_majority = resample(majority_class,\n",
    "                                replace=False,  # set to False for undersampling\n",
    "                                n_samples=len(minority_class),  # match minority class size\n",
    "                                random_state=42)  # for reproducibility\n",
    "\n",
    "# Combine the undersampled majority class with the minority class\n",
    "undersampled_df = pd.concat([undersampled_majority, minority_class])\n",
    "\n",
    "# Shuffle the dataset\n",
    "undersampled_df = undersampled_df.sample(frac=1, random_state=42)\n",
    "\n",
    "# Use the undersampled dataset for further analysis or modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# New Histogram distribtution of isFraud\n",
    "feature = undersampled_df['isFraud']\n",
    "\n",
    "# Create a histogram\n",
    "plt.hist(feature, bins=10)  # Adjust the number of bins as needed\n",
    "\n",
    "# Set labels and title\n",
    "plt.xlabel('isFraud')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Histogram of isFraud')\n",
    "\n",
    "# Display the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assign the features and the label to separate variables\n",
    "\n",
    "X = df.drop(\"isFraud\", axis=1) # Drop the label column and assign the rest to X\n",
    "y = df.loc[:, \"isFraud\"] # Select the label column and assign it to y\n",
    "feature_names = X.columns # Get the names of the feature columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode the categorical variables with one-hot encoding\n",
    "X = pd.get_dummies(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Scaling the numerical variables with min-max scaling\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "X = scaler.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting data into train and test set \n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Building "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create and train a decision tree model\n",
    "\n",
    "dtree = DecisionTreeRegressor(criterion=\"mse\", max_depth=3, random_state=42)\n",
    "dtree.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "# # pip install -U scikit-learn==0.20."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the performance of the model\n",
    "\n",
    "y_pred = dtree.predict(X_test)\n",
    "print(\"Mean squared error:\", mean_squared_error(y_test, y_pred))\n",
    "print(\"Mean absolute error:\", mean_absolute_error(y_test, y_pred))\n",
    "print(\"R2 score:\", r2_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the tree structure\n",
    "plt.figure(figsize=(12,8))\n",
    "plot_tree(dtree, feature_names=feature_names, filled=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the feature importance\n",
    "plt.figure(figsize=(8,6))\n",
    "plt.barh(feature_names, dtree.feature_importances_)\n",
    "plt.xlabel(\"Feature importance\")\n",
    "plt.ylabel(\"Feature name\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the data distribution\n",
    "plt.figure(figsize=(10,8))\n",
    "sns.distplot(y, bins=20)\n",
    "plt.xlabel(\"Fraud probability\")\n",
    "plt.ylabel(\"Density\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the correlation matrix\n",
    "plt.figure(figsize=(10,10))\n",
    "sns.heatmap(X.corr(), annot=True, cmap=\"coolwarm\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the scatter plots of the features vs the target\n",
    "fig, axes = plt.subplots(3, 4, figsize=(15,12))\n",
    "for i, ax in enumerate(axes.flat):\n",
    "    if i < len(feature_names):\n",
    "        ax.scatter(X.iloc[:, i], y, alpha=0.5)\n",
    "        ax.set_xlabel(feature_names[i])\n",
    "        ax.set_ylabel(\"Fraud probability\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
